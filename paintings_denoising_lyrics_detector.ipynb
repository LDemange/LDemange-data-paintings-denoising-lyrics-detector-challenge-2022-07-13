{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d80cb012",
   "metadata": {},
   "source": [
    "## Legend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca11620",
   "metadata": {},
   "source": [
    "üéØ Objective    \n",
    "‚ùì Question  \n",
    "üìù Task  \n",
    "‚òëÔ∏è Instructions  \n",
    "üí° Informations  \n",
    "üíæ Submit your results  \n",
    "\n",
    "**variable name**  \n",
    "*field name*  \n",
    "`python object`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e01f2e",
   "metadata": {},
   "source": [
    "# Reconnaissance de formes par r√©seaux de neurones artificiels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8628f997",
   "metadata": {},
   "source": [
    "This exam assesses the 3rd block of the certification *Reconnaissance de formes par r√©seaux de neurones artificiels*\n",
    "\n",
    "üí° It is split into 2 independent challenges:  \n",
    "- üñºÔ∏è CNN challenge - Image Denoising  \n",
    "- üéôÔ∏è RNN challenge - Lyrics Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f80cd6",
   "metadata": {},
   "source": [
    "# üñºÔ∏è Image Denoising Challenge (2h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b60a06",
   "metadata": {},
   "source": [
    "üéØ Design and train a denoising model  \n",
    "‚òëÔ∏è For a given noisy image $X$, your model should learn to predict the denoised image $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0dfd0f",
   "metadata": {},
   "source": [
    "üí° This challenge assesses the following skills:\n",
    "- C14 Convertir les donn√©es entrantes (images et texte par exemple) en donn√©es adapt√©es pour un r√©seau de neurones (100%)\n",
    "- C15 Ma√Ætriser les diff√©rentes architectures de r√©seau de neurones : convolutifs pour les images & r√©currents pour les s√©ries temporelles et les mod√®les de traitement automatique du langage (NLP) pour le texte (50%)\n",
    "- C16 Utiliser un r√©seau de neurones convolutifs pour √©tiqueter des images (100%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09444354",
   "metadata": {},
   "source": [
    "## 0. Imports\n",
    "\n",
    "‚òëÔ∏è Use the cell below to load the packages you use in this challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc018266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:33:05.954373Z",
     "start_time": "2021-07-02T09:33:05.950711Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd67a8f",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430afb2b",
   "metadata": {},
   "source": [
    "üìù Download the dataset archive  \n",
    "üí° It contains colored as well as black & white images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d9e72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:33:08.673472Z",
     "start_time": "2021-07-02T09:33:07.105177Z"
    }
   },
   "outputs": [],
   "source": [
    "! curl https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/paintings.zip > paintings.zip\n",
    "! unzip -nq \"paintings.zip\" \n",
    "! rm \"paintings.zip\"\n",
    "! ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56b0684",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:33:09.934432Z",
     "start_time": "2021-07-02T09:33:09.914525Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "dataset_paths = glob.glob(\"./paintings/*.jpg\")\n",
    "dataset_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f83608",
   "metadata": {},
   "source": [
    "üìù Display the 16th image of the **dataset_paths**\n",
    "\n",
    "‚òëÔ∏è    Use the `PIL.Image.open</code>` and `matplotlib.pyplot.imshow` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e649f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:34:51.029626Z",
     "start_time": "2021-07-02T09:34:50.854828Z"
    },
    "scrolled": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbb5bbd",
   "metadata": {},
   "source": [
    "Look at the image you just displayed:  \n",
    "üìù Store its shape in `img_shape`  \n",
    "üìù Store its number of dimensions in `img_dim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5fed60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:35:02.076365Z",
     "start_time": "2021-07-02T09:35:02.063108Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfa2f8f",
   "metadata": {},
   "source": [
    "üìù Uncomment the true statements about the image you just displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c7d612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:35:05.854575Z",
     "start_time": "2021-07-02T09:35:05.850307Z"
    }
   },
   "outputs": [],
   "source": [
    "#is_portrait = True\n",
    "#is_portrait = False\n",
    "\n",
    "#is_colored_image = True\n",
    "#is_colored_image = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3a064",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T15:21:44.178889Z",
     "start_time": "2021-10-31T15:21:44.173713Z"
    }
   },
   "source": [
    "üíæ **Run the cell below to submit your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c7af3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:35:07.302574Z",
     "start_time": "2021-07-02T09:35:07.297417Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    'image_data_loading',\n",
    "    img_shape=img_shape,\n",
    "    img_dim=img_dim,\n",
    "    is_portrait=is_portrait,\n",
    "    is_colored_image=is_colored_image\n",
    ")\n",
    "\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03c718",
   "metadata": {},
   "source": [
    "## 2. Processing (50min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08448f33",
   "metadata": {},
   "source": [
    "*C14 Convertir les donn√©es entrantes (images et texte par exemple) en donn√©es adapt√©es pour un r√©seau de neurones (100%)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66adbb66",
   "metadata": {},
   "source": [
    "üìù Store all images from the dataset folder in a `list` of `ndarray` called **dataset_images**\n",
    "\n",
    "üí° It can take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bde7713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:35:15.107490Z",
     "start_time": "2021-07-02T09:35:11.749558Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57a2716",
   "metadata": {},
   "source": [
    "### 2.1 Reshape, Resize, Rescale\n",
    "\n",
    "Simplify your dataset and convert it to a single `ndarray`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c1af3",
   "metadata": {},
   "source": [
    "üí° Recall that your dataset contains colored and black & white images\n",
    "\n",
    "üìù Assign to a `list` **image_dimensions** the two possible number of dimensions for your images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7087ea8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:35:15.974756Z",
     "start_time": "2021-07-02T09:35:15.968528Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2b5fc",
   "metadata": {},
   "source": [
    "üìù Run the cell below to convert all black & white images into colored ones by duplicating the image on three channels  \n",
    "üí° This is for convenience, so as to have only 3D arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9fc55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:35:17.534930Z",
     "start_time": "2021-07-02T09:35:16.787887Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_images = [x if x.ndim==3 else np.repeat(x[:,:,None], 3, axis=2) for x in dataset_images]\n",
    "set([x.ndim for x in dataset_images])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84865561",
   "metadata": {},
   "source": [
    "üìù Resize your images to make sure they have the same shape  \n",
    "\n",
    "‚òëÔ∏è Use the method `tensorflow.image.resize`  \n",
    "‚òëÔ∏è The target size is (height=120 pixels, width=100 pixels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fbc6ae",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff2e87b",
   "metadata": {},
   "source": [
    "üìù Now that all images have the same shape, store them as a `ndarray` in **dataset_resized**  \n",
    "‚òëÔ∏è Make sure that the size of **dataset_resized** is $(n_{images},\\:height,\\:width,\\:channels)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39739658",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:35:18.201904Z",
     "start_time": "2021-07-02T09:35:17.944109Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701f787",
   "metadata": {},
   "source": [
    "üìù Store in **dataset_scaled** your scaled images  \n",
    "‚òëÔ∏è All scaled values should be between $0$ and $1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c7002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:35:18.255378Z",
     "start_time": "2021-07-02T09:35:18.204011Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdeeb0f",
   "metadata": {},
   "source": [
    "### 2.2 Create (X, y) sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe8c8f",
   "metadata": {},
   "source": [
    "üìù Run the cell below to add random noise to your images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd79f84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:35:19.762284Z",
     "start_time": "2021-07-02T09:35:19.154308Z"
    }
   },
   "outputs": [],
   "source": [
    "NOISE_LEVEL = 0.2\n",
    "\n",
    "dataset_noisy = np.clip(\n",
    "    dataset_scaled + np.random.normal(\n",
    "        loc=0,\n",
    "        scale=NOISE_LEVEL,\n",
    "        size=dataset_scaled.shape\n",
    "    ).astype(np.float32),\n",
    "    0,\n",
    "    1\n",
    ")\n",
    "dataset_noisy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a31c361",
   "metadata": {},
   "source": [
    "üìù Plot a noisy image alongside the normal one to visualize the impact of the random noise you just added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01e70bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:35:29.724857Z",
     "start_time": "2021-07-02T09:35:29.488078Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d72d4f7",
   "metadata": {},
   "source": [
    "üìù **Create your `(X_train, Y_train)`, `(X_test, Y_test)` train and test sets**  \n",
    "‚òëÔ∏è Use `sklearn`'s `train_test_split` method  \n",
    "‚òëÔ∏è Your test set should consist of 20% of your total observations, randomly sampled  \n",
    "üí° Recall your objective: *For a given noisy image $X$, your model should learn to predict the denoised image $y$* to choose $X$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76718804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:35:35.857778Z",
     "start_time": "2021-07-02T09:35:35.773969Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d5d32a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T15:21:44.178889Z",
     "start_time": "2021-10-31T15:21:44.173713Z"
    }
   },
   "source": [
    "üíæ **Run the cell below to submit your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25305b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:35:42.369782Z",
     "start_time": "2021-07-02T09:35:42.325003Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    \"image_preprocessing\",\n",
    "    X_train_shape = X_train.shape,\n",
    "    Y_train_shape = Y_train.shape,\n",
    "    X_std = X_train[:,:,:,0].std(),\n",
    "    Y_std = Y_train[:,:,:,0].std(),\n",
    "    first_image = Y_train[0]\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d0de6c",
   "metadata": {},
   "source": [
    "## 3. Convolutional Neural Network (1h10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b56afa",
   "metadata": {},
   "source": [
    "*C15 Ma√Ætriser les diff√©rentes architectures de r√©seau de neurones : convolutifs pour les images & r√©currents pour les s√©ries temporelles et les mod√®les de traitement automatique du langage (NLP) pour le texte (50%)*  \n",
    "\n",
    "*C16 Utiliser un r√©seau de neurones convolutifs pour √©tiqueter des images (100%)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a8296",
   "metadata": {},
   "source": [
    "A commonly used neural network architecture for image denoising is the __AutoEncoder__.\n",
    "\n",
    "<img src='https://github.com/lewagon/data-images/blob/master/DL/autoencoder.png?raw=true'>\n",
    "\n",
    "Its goal is to learn a compact representation of your data to reconstruct them as precisely as possible.  \n",
    "The loss for such model must incentivize it to have __an output as close to the input as possible__.\n",
    "\n",
    "For this challenge, __you will only be asked to code the Encoder part of the network__, since building a Decoder leverages layers architectures you are not familiar with (yet)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82ac7a1",
   "metadata": {},
   "source": [
    "**If you haven't managed to build your own (X,Y) training sets**  \n",
    "üìù Copy and paste the code snippet below in a new cell and run it    \n",
    "üí° It will give you clean `(X_train, Y_train)`, `(X_test, Y_test)` for this section\n",
    "\n",
    "```python\n",
    "! curl https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/data_painting_solution.pickle > data_painting_solution.pickle\n",
    "\n",
    "import pickle\n",
    "with open(\"data_painting_solution.pickle\", \"rb\") as file:\n",
    "    (X_train, Y_train, X_test, Y_test) = pickle.load(file)\n",
    "    \n",
    "! rm data_painting_solution.pickle\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866bfbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/data_painting_solution.pickle > data_painting_solution.pickle\n",
    "\n",
    "import pickle\n",
    "with open(\"data_painting_solution.pickle\", \"rb\") as file:\n",
    "    (X_train, Y_train, X_test, Y_test) = pickle.load(file)\n",
    "\n",
    "! rm data_painting_solution.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0453fe06",
   "metadata": {},
   "source": [
    "### 3.1 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ea5abf",
   "metadata": {},
   "source": [
    "üìù Run the cell below that defines the **decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa778c4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:37:03.877037Z",
     "start_time": "2021-07-02T09:37:03.761216Z"
    }
   },
   "outputs": [],
   "source": [
    "# We choose to compress images into a latent_dimension of size 6000\n",
    "latent_dimensions = 6000\n",
    "\n",
    "# We build a decoder that takes 1D-vectors of size 6000 to reconstruct images of shape (120,100,3)\n",
    "decoder = Sequential(name='decoder')\n",
    "decoder.add(layers.Reshape((30, 25, 8), input_dim=latent_dimensions))\n",
    "decoder.add(layers.Conv2DTranspose(filters=16, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "decoder.add(layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "decoder.add(layers.Conv2D(filters=3, kernel_size=3, padding=\"same\", activation=\"sigmoid\"))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6898a0",
   "metadata": {},
   "source": [
    "üìù Store in **encoder** a model defined using `Sequential` that plugs correctly with the **decoder** defined above  \n",
    "\n",
    "‚òëÔ∏è The output of your **encoder**, before flattening, is the same shape as the input of the **decoder**  \n",
    "‚òëÔ∏è Use a convolutional neural network architecture without transfer learning  \n",
    "‚òëÔ∏è Keep it simple  \n",
    "‚òëÔ∏è Print model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984a5459",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:37:05.122352Z",
     "start_time": "2021-07-02T09:37:05.095337Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a5b6a",
   "metadata": {},
   "source": [
    "üìù Run the cell below to construct the full **autoencoder**  \n",
    "‚òëÔ∏è Look carefully at the summary to make sure your **encoder** fits with the **decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5222bca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:37:06.320520Z",
     "start_time": "2021-07-02T09:37:06.273266Z"
    }
   },
   "outputs": [],
   "source": [
    "x = layers.Input(shape=(120, 100, 3))\n",
    "autoencoder = Model(x, decoder(encoder(x)), name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85758852",
   "metadata": {},
   "source": [
    "### 3.2 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0f3c1",
   "metadata": {},
   "source": [
    "üìù Store in **score_baseline** your baseline score  \n",
    "‚òëÔ∏è Use the Mean Absolute Error  \n",
    "‚òëÔ∏è Your baseline is the *'dumb'* case where you don't manage to denoise anything at all  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d589a9bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:37:08.363329Z",
     "start_time": "2021-07-02T09:37:08.332923Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def7c160",
   "metadata": {},
   "source": [
    "üìù Train your **autoencoder**\n",
    "\n",
    "‚òëÔ∏è Use an appropriate loss for the task at hand  \n",
    "‚òëÔ∏è Make sure your model does not overfit\n",
    "\n",
    "üí° You will not be judged by the computing power of your computer, your training should last under 3 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5ec508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:37:09.655742Z",
     "start_time": "2021-07-02T09:37:09.641065Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ef73b",
   "metadata": {},
   "source": [
    "üìù Plot your training and validation loss at each epoch  \n",
    "‚òëÔ∏è Save your figure as **history_cnn.png** in the **tests/** directory  \n",
    "‚òëÔ∏è Make sure to keep the code below at the end of the cell that contains your plots  \n",
    "```python\n",
    "fig = plt.gcf()\n",
    "fig.savefig(\"tests/history_cnn.png\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e61180",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:38:12.503826Z",
     "start_time": "2021-07-02T09:38:12.477619Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot below your train/val loss history\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Run this code to save your figure as png in the tests folder\n",
    "fig = plt.gcf()\n",
    "fig.savefig(\"tests/history_cnn.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c8d885",
   "metadata": {},
   "source": [
    "üìù Evaluate your performances on your test set  \n",
    "‚òëÔ∏è Store in **Y_pred** your denoised test set  \n",
    "‚òëÔ∏è Store in **score_test** your Mean Absolute Error using **Y_pred** and **Y_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13d748f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:38:16.078595Z",
     "start_time": "2021-07-02T09:38:15.780624Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7a63d9",
   "metadata": {},
   "source": [
    "üìù Run the cell below to check your result on several image  \n",
    "üí° We asked for a small model, so don't worry if your prediction seems in significantly lower quality than the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60816a03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:40:41.062550Z",
     "start_time": "2021-07-02T09:40:40.590459Z"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(index=range(X_test.shape[0]))\n",
    "def plot(index):\n",
    "    idx = index\n",
    "\n",
    "    fig, axs = plt.subplots(1,3, figsize=(10,5))\n",
    "    axs[0].imshow(Y_test[idx])\n",
    "    axs[0].set_title(\"Clean image.\")\n",
    "\n",
    "    axs[1].imshow(X_test[idx])\n",
    "    axs[1].set_title(\"Noisy image.\")\n",
    "\n",
    "    axs[2].imshow(Y_pred[idx])\n",
    "    axs[2].set_title(\"Prediction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c46729",
   "metadata": {},
   "source": [
    "üìù Choose one of your predicted denoised image and save it  \n",
    "‚òëÔ∏è The target path is **tests/image_denoised.png**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb8209",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7b71cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T15:21:44.178889Z",
     "start_time": "2021-10-31T15:21:44.173713Z"
    }
   },
   "source": [
    "üíæ **Run the cell below to submit your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce318da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:40:52.917607Z",
     "start_time": "2021-07-02T09:40:52.905810Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "from tensorflow import size\n",
    "\n",
    "result = ChallengeResult(\n",
    "    \"image_network\",\n",
    "    input_shape = list(encoder.input.shape),\n",
    "    output_shape = list(encoder.output.shape),\n",
    "    layer_names = [layer.name for layer in encoder.layers],\n",
    "    trainable_params = sum([size(w_matrix).numpy() for w_matrix in encoder.trainable_variables]),\n",
    "    score_baseline = score_baseline,\n",
    "    score_test = score_test,\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677705d0",
   "metadata": {},
   "source": [
    "# üéôÔ∏è Lyrics detector Challenge (1h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b0807f",
   "metadata": {},
   "source": [
    "üéØ Design and train a lyrics classifier  \n",
    "‚òëÔ∏è For a given verse $X$, your model should learn to predict the artist $y$  \n",
    "üí° For this challenge the data processing is given"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb56507",
   "metadata": {},
   "source": [
    "üí° This challenge assesses the following skills:\n",
    "- C15 Ma√Ætriser les diff√©rentes architectures de r√©seau de neurones : convolutifs pour les images & r√©currents pour les s√©ries temporelles et les mod√®les de traitement automatique du langage (NLP) pour le texte (50%)\n",
    "- C17 Utiliser un r√©seau de neurones pour comprendre l'intention d'une phrase en langage naturel (100%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8941916a",
   "metadata": {},
   "source": [
    "## 0. Imports\n",
    "\n",
    "‚òëÔ∏è Use the cell below to load the packages you use in this challenge  \n",
    "üí° All packages used in the (given) preprocessing are imported here, make sure to not delete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8539678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T08:31:43.491944Z",
     "start_time": "2021-07-02T08:31:37.265021Z"
    }
   },
   "outputs": [],
   "source": [
    "# Arrays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Processing\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7498b857",
   "metadata": {},
   "source": [
    "## 1. Load Data (given)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece36ff7",
   "metadata": {},
   "source": [
    "üìù Let's download the dataset  \n",
    "‚òëÔ∏è Keep the original, unaltered data in **raw_data** and work with its copy, **data**  \n",
    "üí° It contains around 4k verses of lyrics from 3 different artists (Drake, Ed Sheeran and Kanye West)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff73cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.654079Z",
     "start_time": "2021-06-25T17:22:16.207433Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/verses.csv\")\n",
    "data = raw_data.copy()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d271ead6",
   "metadata": {},
   "source": [
    "üìù  Look at the 19th verse  \n",
    "üí° Notice the unicode characters, for instance `\\u2005`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0def904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.663663Z",
     "start_time": "2021-06-25T17:22:16.658103Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data.verse[18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ed4ff3",
   "metadata": {},
   "source": [
    "üìù Run the cell below to decode unicode characters  \n",
    "üí° We provide you with a method using [`unidecode.unidecode()`](https://pypi.org/project/Unidecode/) to do so  \n",
    "‚òëÔ∏è Install the `unidecode` package if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa8648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.840659Z",
     "start_time": "2021-06-25T17:22:16.666254Z"
    }
   },
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "data[\"verse\"] = data[\"verse\"].map(unidecode)\n",
    "data.verse[18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a129928",
   "metadata": {},
   "source": [
    "üìù Run the cell below to drop duplicated verses    \n",
    "üí° Observing duplicates happens quite often with music lyrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8283ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of duplicated verses\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a5355c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.851521Z",
     "start_time": "2021-06-25T17:22:16.842793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop duplicated verses\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Check again to ensure there are 0 duplicates remaining\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee219b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T15:21:44.178889Z",
     "start_time": "2021-10-31T15:21:44.173713Z"
    }
   },
   "source": [
    "üíæ **Run the cell below to submit your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8f7dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.861084Z",
     "start_time": "2021-06-25T17:22:16.854026Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    'lyrics_data_loading',\n",
    "    shape=data.shape,\n",
    "    verses=data.verse[:50]\n",
    ")\n",
    "\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e1933d",
   "metadata": {},
   "source": [
    "## 2. Processing (given)\n",
    "\n",
    "‚òëÔ∏è For this section, read carefully before running the cells, you will need to understand the processing to design an train your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb5e39d",
   "metadata": {},
   "source": [
    "üìù Transform the list of strings (verses) into a list of word sequences  \n",
    "üí° These sequences of words are stored in a new column *seq* in your **data**  \n",
    "üí° We use `tensorflow.keras.preprocessing.text.text_to_word_sequence` to achieve this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f7c19e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.569442Z",
     "start_time": "2021-06-25T17:22:19.478291Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"seq\"] = [text_to_word_sequence(verse) for verse in data[\"verse\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d82c70",
   "metadata": {},
   "source": [
    "üìù Check the distribution of sequences lengths  \n",
    "üí° From this we choose to limit ourself to 300 words per verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d330ad0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.783874Z",
     "start_time": "2021-06-25T17:22:19.572393Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(x=data[\"seq\"].map(lambda l: len(l)),\n",
    "            hue=[x for x in data[\"artist\"]],\n",
    "            common_norm=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb24de1d",
   "metadata": {},
   "source": [
    "üìù Truncate each sequences to keep only the first `300` words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25809e0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.797635Z",
     "start_time": "2021-06-25T17:22:19.786221Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"seq\"] = data[\"seq\"].map(lambda x: x[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d8b9a8",
   "metadata": {},
   "source": [
    "üìù Train a `gensim.models.Word2Vec` model on your dataset\n",
    "- You want to embed each word into vectors of dimension `100`\n",
    "- No words should be excluded\n",
    "- Give Word2Vec at least 50 epochs to be sure it converges\n",
    "- Store these lists of vectors in a new column `data[\"embed\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab278862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:26.587185Z",
     "start_time": "2021-06-25T17:22:19.799947Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec(\n",
    "    sentences=data[\"seq\"],\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=0,\n",
    "    epochs=50, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd7e74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:27.632783Z",
     "start_time": "2021-06-25T17:22:26.589556Z"
    }
   },
   "outputs": [],
   "source": [
    "data['embed'] = [[word2vec.wv[word] for word in verse] \n",
    "                 for verse in data['seq']]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac783bca",
   "metadata": {},
   "source": [
    "üìù  Create your a `ndarray` **X** of shape $(number\\_of\\_verses,\\ maximum\\_sequence\\_length,\\ embedding\\_size)$\n",
    "\n",
    "üí° Keep 300 words per verse (verses shorter than 300 are padded with zeros at the end) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84386d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:28.272086Z",
     "start_time": "2021-06-25T17:22:27.638449Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pad_sequences(\n",
    "    data[\"embed\"],\n",
    "    dtype='float',\n",
    "    padding='post'\n",
    ")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df39cad",
   "metadata": {},
   "source": [
    "üìù  Create your a `ndarray` **y** of shape $(number\\_of\\_verses,\\ number\\_of\\_classes)$ that contains the one-hot encoded list of labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1a1ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:28.394015Z",
     "start_time": "2021-06-25T17:22:28.274638Z"
    }
   },
   "outputs": [],
   "source": [
    "y = OneHotEncoder().fit_transform(data[['artist']]).toarray()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6980b008",
   "metadata": {},
   "source": [
    "üìù Split the dataset to create both the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4249164",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:29.558686Z",
     "start_time": "2021-06-25T17:22:28.400774Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934d431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T15:21:44.178889Z",
     "start_time": "2021-10-31T15:21:44.173713Z"
    }
   },
   "source": [
    "üíæ **Run the cell below to submit your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2350cfde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:29.803743Z",
     "start_time": "2021-06-25T17:22:29.563431Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    'lyrics_data_preprocessing',\n",
    "    n_zeros = np.sum(X == 0),\n",
    "    X_shape = X.shape,\n",
    "    y_shape = y.shape,\n",
    ")\n",
    "\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f666e449",
   "metadata": {},
   "source": [
    "## 3. Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9017ce5",
   "metadata": {},
   "source": [
    "*C15 Ma√Ætriser les diff√©rentes architectures de r√©seau de neurones : convolutifs pour les images & r√©currents pour les s√©ries temporelles et les mod√®les de traitement automatique du langage (NLP) pour le texte (50%)*  \n",
    "\n",
    "*C17 Utiliser un r√©seau de neurones pour comprendre l'intention d'une phrase en langage naturel (100%)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df4efd3",
   "metadata": {},
   "source": [
    "üìù Store in **score_baseline** your baseline score  \n",
    "‚òëÔ∏è Use the Accuracy  \n",
    "‚òëÔ∏è Your baseline is the 'dumb' case where you predict only the most frequent artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb30c0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:33.555223Z",
     "start_time": "2021-06-25T17:22:33.547120Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b633c37e",
   "metadata": {},
   "source": [
    "üìù Store in **model** using `Sequential`\n",
    "‚ùì **Create a RNN architecture to predict the artists `y`  given verses `X`** :\n",
    "\n",
    "‚òëÔ∏è Use a recurrent neural network architecture  \n",
    "‚òëÔ∏è Keep it simple: use only one LSTM or GRU layer  \n",
    "‚òëÔ∏è Limit yourself to one *hidden* dense layer between the LSTM/GRU layer and the output layer  \n",
    "‚òëÔ∏è Don't forget to take care of the fake \"zeros\" added when padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4775201",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:27:09.448283Z",
     "start_time": "2021-06-25T17:27:08.796094Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d9b97",
   "metadata": {},
   "source": [
    "üìù Train your **model**\n",
    "\n",
    "‚òëÔ∏è Use an appropriate loss for the task at hand  \n",
    "‚òëÔ∏è Make sure your model does not overfit\n",
    "\n",
    "üí° You will not be judged by the computing power of your computer, your training should last under 3 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af9a5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:28:13.790957Z",
     "start_time": "2021-06-25T17:27:09.537171Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f464ba4",
   "metadata": {},
   "source": [
    "üìù Plot your training and validation loss at each epoch  \n",
    "‚òëÔ∏è Save your figure as **history_rnn.png** in the **tests/** directory  \n",
    "‚òëÔ∏è Make sure to keep the code below at the end of the cell that contains your plots  \n",
    "```python\n",
    "fig = plt.gcf()\n",
    "fig.savefig(\"tests/history_rnn.png\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c959e1fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:28:13.814449Z",
     "start_time": "2021-06-25T17:28:13.793297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot below your train/val loss history\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Run also this code to save figure as jpg in path below (it's your job to ensure it works)\n",
    "fig = plt.gcf()\n",
    "plt.savefig(\"tests/history_rnn.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c161566",
   "metadata": {},
   "source": [
    "üìù Evaluate your performances on your test set  \n",
    "‚òëÔ∏è Use the `evaluate` method a `Sequential` model to do so  \n",
    "‚òëÔ∏è Store the resulting accuracy score in **score_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673ca947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:29:15.350717Z",
     "start_time": "2021-06-25T17:29:14.925473Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c303e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T15:21:44.178889Z",
     "start_time": "2021-10-31T15:21:44.173713Z"
    }
   },
   "source": [
    "üíæ **Run the cell below to submit your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158b7b52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:25:11.216908Z",
     "start_time": "2021-06-25T17:25:11.208773Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    \"lyrics_network\",\n",
    "    loss = model.loss,\n",
    "    input_shape = list(model.input.shape),\n",
    "    layer_names = [layer.name for layer in model.layers],\n",
    "    final_activation = model.layers[-1].activation.__wrapped__._keras_api_names[0],\n",
    "    score_baseline = score_baseline,\n",
    "    score_test = score_test,\n",
    ")\n",
    "result.write()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
